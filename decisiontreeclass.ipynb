{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree based learning algorithms are considered to be one of the best and mostly used supervised learning methods. Tree based methods empower predictive models with high accuracy, stability and ease of interpretation. Unlike linear models, they map non-linear relationships quite well. They are adaptable at solving any kind of problem at hand (classification or regression).\n",
    "\n",
    "Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\n",
    "\n",
    "How does a tree decide where to split?\n",
    "The decision of making strategic splits heavily affects a treeâ€™s accuracy. The decision criteria is different for classification and regression trees.\n",
    "\n",
    "Decision trees use multiple algorithms to decide to split a node in two or more sub-nodes. The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that purity of the node increases with respect to the target variable. Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes. Gini Index is one of the methods for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('iris.csv')\n",
    "\n",
    "#replacing all missing data with NaN value\n",
    "df.replace('?',np.nan,inplace=True)\n",
    "\n",
    "#deleting the column with id, 1 in the argument indicates 'column', so this will delete the 'column' containing 'id'\n",
    "#df.drop(['id'],1,inplace=True)\n",
    "\n",
    "#delete all the rows that have NaN in them\n",
    "dk=df.dropna()\n",
    "full_data=dk.astype(float).values.tolist()\n",
    "headers = df.dtypes.index\n",
    "header=headers.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1', 'x2', 'label']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data, not necessary but if done the results are more accurate\n",
    "random.shuffle(full_data)\n",
    "\n",
    "test_size1=0.1\n",
    "train_data1=full_data[:-int(test_size1*len(full_data))]\n",
    "test_data1=full_data[-int(test_size1*len(full_data)):]\n",
    "\n",
    "test_size2=0.5\n",
    "train_data2=full_data[:-int(test_size2*len(full_data))]\n",
    "test_data2=full_data[-int(test_size2*len(full_data)):]\n",
    "\n",
    "test_size3=0.3\n",
    "train_data3=full_data[:-int(test_size3*len(full_data))]\n",
    "test_data3=full_data[-int(test_size3*len(full_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    def __init__(self,column,value):\n",
    "        '''function to take the value and the index of the element in the list\n",
    "        eg: suppose the list is ['Green',3,'Apple'], now if column=1 and value='Green' '''\n",
    "        self.column=column\n",
    "        self.value=value\n",
    "    \n",
    "    def match(self,example):\n",
    "        '''function to check the element at the column of the passed list and compare it to the value passed to the question\n",
    "        if column=1 and value='Green' and the above list is passed then the function will return True '''\n",
    "        val=example[self.column]\n",
    "        return val==self.value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Is %s == %s ?\" %(header[self.column],str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTF is Decision tree functions\n",
    "class DTF:            \n",
    "    def unique_values(self,data,col):\n",
    "        '''function to take dataset as agrument and returns a set of the elements in the dataset'''\n",
    "        return (set(row[col] for row in data))\n",
    "    \n",
    "    \n",
    "    def class_counts(self,data):\n",
    "        '''fucntion to count the number of times the element(output) is present in the set'''\n",
    "        self.counts={}\n",
    "        for row in data:\n",
    "            self.label=row[-1]\n",
    "            \n",
    "            #if item isn't present in the dictionary then initialize its count to 0\n",
    "            \n",
    "            if self.label not in self.counts:\n",
    "                self.counts[self.label]=0\n",
    "                \n",
    "            #increment the count of the element that is found\n",
    "            \n",
    "            self.counts[self.label]+=1\n",
    "        return self.counts\n",
    "    \n",
    "    def is_numeric(self,value):\n",
    "        '''function returns True if the value is int or float'''\n",
    "        return(isinstance(self.value,int) or isinstance(self.value,float))\n",
    "    \n",
    "    def partition(self,rows, question):\n",
    "        '''function to generate true_list and false_list by appending rows that satisfy the question'''\n",
    "        self.true_rows,self.false_rows=[],[]\n",
    "        for row in rows:\n",
    "            if question.match(row):\n",
    "                self.true_rows.append(row)\n",
    "            else:\n",
    "                self.false_rows.append(row)\n",
    "        return self.true_rows,self.false_rows\n",
    "    \n",
    "    def gini(self,rows):\n",
    "        self.counts=self.class_counts(rows)\n",
    "        self.impurity=1\n",
    "        for output in self.counts:\n",
    "            self.probability_output=self.counts[output]/float(len(rows))\n",
    "            self.impurity-=self.probability_output**2\n",
    "        return self.impurity\n",
    "    \n",
    "    def info_gain(self,left,right,current_uncertainity):\n",
    "        self.p=len(left)/float(len(left)+len(right))\n",
    "        return (current_uncertainity-self.p*self.gini(left)-(1-self.p)*self.gini(right))\n",
    "        \n",
    "    def find_best_split(self,rows):\n",
    "        self.best_gain=0\n",
    "        self.best_question=None\n",
    "        \n",
    "        self.current_uncertainity=self.gini(rows)\n",
    "        self.n_features=len(rows[0])-1\n",
    "        \n",
    "        for col in range(self.n_features):\n",
    "            self.values=self.unique_values(rows,col)\n",
    "            \n",
    "            for val in self.values:\n",
    "                self.question=Question(col,val)\n",
    "                self.true_rows,self.false_rows=self.partition(rows,self.question)\n",
    "                if len(self.true_rows)==0 or len(self.false_rows)==0:\n",
    "                    continue\n",
    "                self.gain=self.info_gain(self.true_rows,self.false_rows,self.current_uncertainity)\n",
    "                if self.gain>=self.best_gain:\n",
    "                    self.best_gain=self.gain\n",
    "                    self.best_question=self.question\n",
    "                    \n",
    "            return self.best_gain,self.best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self,rows):\n",
    "        self.DTF=DTF()\n",
    "        self.prediction=self.DTF.class_counts(rows)\n",
    "        \n",
    "class Decision_Node:\n",
    "    def __init__(self,question,true_branch,false_branch):\n",
    "        self.question=question\n",
    "        self.true_branch=true_branch\n",
    "        self.false_branch=false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Tree(DTF):\n",
    "    def __init__(self):\n",
    "        self.DTF=DTF() \n",
    "                \n",
    "    def build_tree(self,training_data):\n",
    "        self.gain,self.question=self.DTF.find_best_split(training_data)\n",
    "        if self.gain==0:\n",
    "            return Leaf(training_data)\n",
    "        \n",
    "        self.true_rows, self.false_rows=self.DTF.partition(training_data,self.question)\n",
    "        self.DecisionNode=Decision_Node(self.question,self.build_tree(self.true_rows),self.build_tree(self.false_rows))\n",
    "        return self.DecisionNode\n",
    "    \n",
    "    def print_tree(self,node,spacing=''):\n",
    "        if isinstance(node,Leaf):\n",
    "            print (spacing,'Predict',node.prediction)\n",
    "            return\n",
    "        print (spacing,str(node.question))\n",
    "        print (spacing,'--> True')\n",
    "        self.print_tree(node.true_branch,spacing+'  ')\n",
    "        print (spacing,'--> False')\n",
    "        self.print_tree(node.false_branch,spacing+'  ')\n",
    "        \n",
    "    def classify(self,row,node):\n",
    "        if isinstance(node,Leaf):\n",
    "            return node.prediction\n",
    "        if node.question.match(row):\n",
    "            return self.classify(row,node.true_branch)\n",
    "        else:\n",
    "            return self.classify(row,node.false_branch)\n",
    "        \n",
    "    def print_leaf(self,counts):\n",
    "        self.total=sum(counts.values())*1.0\n",
    "        self.probs={}\n",
    "        for lbl in counts.keys():\n",
    "            self.probs[lbl]=str(int(counts[lbl]/self.total*100))+'%'\n",
    "        return self.probs\n",
    "    \n",
    "    def predict(self,testing_data,node):\n",
    "        for row in testing_data:\n",
    "            print (row[-1], self.print_leaf(self.classify(row,node)))\n",
    "            \n",
    "    def accuracy(self,testing_data,node):\n",
    "        self.correct=0\n",
    "        self.all=0\n",
    "        for row in testing_data:\n",
    "            self.result=self.print_leaf(self.classify(row,node))\n",
    "            if row[-1]==max(self.result, key=self.result.get):\n",
    "                self.correct+=1\n",
    "        return self.correct/float(len(testing_data))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1=Decision_Tree()\n",
    "dt2=Decision_Tree()\n",
    "dt3=Decision_Tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree1=dt1.build_tree(train_data1)\n",
    "my_tree2=dt2.build_tree(train_data2)\n",
    "my_tree3=dt3.build_tree(train_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is x1 == 1.5 ?\n",
      " --> True\n",
      "   Predict {0.0: 13}\n",
      " --> False\n",
      "   Is x1 == 1.4 ?\n",
      "   --> True\n",
      "     Predict {0.0: 12}\n",
      "   --> False\n",
      "     Is x1 == 1.3 ?\n",
      "     --> True\n",
      "       Predict {0.0: 7}\n",
      "     --> False\n",
      "       Is x1 == 1.6 ?\n",
      "       --> True\n",
      "         Predict {0.0: 7}\n",
      "       --> False\n",
      "         Is x1 == 1.7 ?\n",
      "         --> True\n",
      "           Predict {0.0: 4}\n",
      "         --> False\n",
      "           Is x1 == 1.2 ?\n",
      "           --> True\n",
      "             Predict {0.0: 2}\n",
      "           --> False\n",
      "             Is x1 == 1.9 ?\n",
      "             --> True\n",
      "               Predict {0.0: 2}\n",
      "             --> False\n",
      "               Is x1 == 1.1 ?\n",
      "               --> True\n",
      "                 Predict {0.0: 1}\n",
      "               --> False\n",
      "                 Is x1 == 1.0 ?\n",
      "                 --> True\n",
      "                   Predict {0.0: 1}\n",
      "                 --> False\n",
      "                   Predict {1.0: 41}\n"
     ]
    }
   ],
   "source": [
    "dt1.print_tree(my_tree1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is x1 == 1.4 ?\n",
      " --> True\n",
      "   Predict {0.0: 7}\n",
      " --> False\n",
      "   Is x1 == 1.5 ?\n",
      "   --> True\n",
      "     Predict {0.0: 7}\n",
      "   --> False\n",
      "     Is x1 == 1.6 ?\n",
      "     --> True\n",
      "       Predict {0.0: 5}\n",
      "     --> False\n",
      "       Is x1 == 1.7 ?\n",
      "       --> True\n",
      "         Predict {0.0: 3}\n",
      "       --> False\n",
      "         Is x1 == 1.3 ?\n",
      "         --> True\n",
      "           Predict {0.0: 3}\n",
      "         --> False\n",
      "           Is x1 == 1.1 ?\n",
      "           --> True\n",
      "             Predict {0.0: 1}\n",
      "           --> False\n",
      "             Predict {1.0: 24}\n"
     ]
    }
   ],
   "source": [
    "dt1.print_tree(my_tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0 % training data Accuracy 100.0\n",
      "50.0 % training data Accuracy 90.0\n",
      "70.0 % training data Accuracy 93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "print (100-test_size1*100,'% training data','Accuracy',dt1.accuracy(test_data1,my_tree1))\n",
    "print (100-test_size2*100,'% training data','Accuracy',dt2.accuracy(test_data2,my_tree2))\n",
    "print (100-test_size3*100,'% training data','Accuracy',dt3.accuracy(test_data3,my_tree3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
